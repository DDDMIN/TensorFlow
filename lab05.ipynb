{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab05",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOI9f5NOm5oIZ0t5iGlgJje",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDDMIN/TensorFlow/blob/main/lab05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uiUiZ2YbwPi",
        "outputId": "f075e984-84d7-40c5-f071-f68e382e77ec"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\r\n",
        "tf.disable_v2_behavior()\r\n",
        "\r\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]] #x1, x2\r\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\r\n",
        "\r\n",
        "#placeholders for a tensor that will be always fed.\r\n",
        "X = tf.placeholder(tf.float32, shape = [None, 2]) #n개의 dataset, dataset 당 x숫자\r\n",
        "Y = tf.placeholder(tf.float32, shape = [None, 1])\r\n",
        "W = tf.Variable(tf.random_normal([2, 1]), name = 'weight') #2행 1열의 weight\r\n",
        "b = tf.Variable(tf.random_normal([1])) #상수 b\r\n",
        "\r\n",
        "#hypothesis using sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(X, W) + b))\r\n",
        "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\r\n",
        "\r\n",
        "#cost/loss function\r\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\r\n",
        "\r\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost) #미분해서 cost 최소화\r\n",
        "\r\n",
        "\r\n",
        "#Accuracy computation\r\n",
        "#True if hypothesis > 0.5 else False 0.5초과는 pass 이하는 fail\r\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) #비교문 결과 True, False를 tf.float하면 1,0으로 변환됨#Accuracy computation\r\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32)) #예상결과 predicted 와 실제값 Y를 비교. 비교결과의 평균값\r\n",
        "\r\n",
        "#Launch graph\r\n",
        "with tf.Session() as sess:\r\n",
        "  #initialize TesnorFlow variables\r\n",
        "  sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "  for step in range(10001):\r\n",
        "    cost_val, _ = sess.run([cost,train], feed_dict = {X: x_data, Y: y_data})\r\n",
        "    if step % 200 == 0:\r\n",
        "      print(step, cost_val)\r\n",
        "  h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X: x_data, Y: y_data})\r\n",
        "  print(\"\\nHypothesis: \", h, \"\\nCorrect(Y): \", c, \"\\nAccuracy: \", a)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.78870916\n",
            "200 0.5999866\n",
            "400 0.57817125\n",
            "600 0.55719006\n",
            "800 0.5370391\n",
            "1000 0.51771414\n",
            "1200 0.49920735\n",
            "1400 0.4815072\n",
            "1600 0.46459854\n",
            "1800 0.44846272\n",
            "2000 0.43307814\n",
            "2200 0.41842043\n",
            "2400 0.4044638\n",
            "2600 0.3911805\n",
            "2800 0.37854195\n",
            "3000 0.36651945\n",
            "3200 0.3550838\n",
            "3400 0.34420618\n",
            "3600 0.33385828\n",
            "3800 0.32401237\n",
            "4000 0.31464142\n",
            "4200 0.30571997\n",
            "4400 0.297223\n",
            "4600 0.28912687\n",
            "4800 0.28140905\n",
            "5000 0.27404812\n",
            "5200 0.26702377\n",
            "5400 0.26031712\n",
            "5600 0.25390998\n",
            "5800 0.24778526\n",
            "6000 0.24192719\n",
            "6200 0.23632069\n",
            "6400 0.23095173\n",
            "6600 0.22580697\n",
            "6800 0.22087413\n",
            "7000 0.21614164\n",
            "7200 0.21159838\n",
            "7400 0.2072344\n",
            "7600 0.20303999\n",
            "7800 0.19900621\n",
            "8000 0.19512475\n",
            "8200 0.19138753\n",
            "8400 0.18778728\n",
            "8600 0.18431704\n",
            "8800 0.18097015\n",
            "9000 0.17774062\n",
            "9200 0.17462271\n",
            "9400 0.17161106\n",
            "9600 0.16870038\n",
            "9800 0.16588597\n",
            "10000 0.16316342\n",
            "\n",
            "Hypothesis:  [[0.03669158]\n",
            " [0.16620329]\n",
            " [0.3321877 ]\n",
            " [0.76916456]\n",
            " [0.9316164 ]\n",
            " [0.9775359 ]] \n",
            "Correct(Y):  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] \n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}