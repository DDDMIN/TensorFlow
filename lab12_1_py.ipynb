{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab12-1.py",
      "provenance": [],
      "authorship_tag": "ABX9TyOz3cD5jDHGNQk+QFDrTsho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDDMIN/TensorFlow/blob/main/lab12_1_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y09JO1YFsnLH",
        "outputId": "19971e71-70a5-448f-a97b-354710bcb18a"
      },
      "source": [
        "# Lab 12 RNN\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
        "# Teach hello: hihell -> ihello\n",
        "# x_data = [[0, 1, 0, 2, 3, 3]]  # hihell\n",
        "y_data = [[1, 0, 2, 3, 3, 4]]  # ihello\n",
        "\n",
        "num_classes = 5\n",
        "input_dim = 5  # one-hot size, same as hidden_size to directly predict one-hot\n",
        "sequence_length = 6  # |ihello| == 6\n",
        "learning_rate = 0.1\n",
        "\n",
        "x_one_hot = np.array([[[1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 1, 0, 0, 0],    # i 1\n",
        "                       [1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 0, 1, 0, 0],    # e 2\n",
        "                       [0, 0, 0, 1, 0],    # l 3\n",
        "                       [0, 0, 0, 1, 0]]],  # l 3\n",
        "                     dtype=np.float32)\n",
        "\n",
        "y_one_hot = tf.keras.utils.to_categorical(y_data, num_classes=num_classes)\n",
        "print(x_one_hot.shape)\n",
        "print(y_one_hot.shape)\n",
        "\n",
        "tf.model = tf.keras.Sequential()\n",
        "\n",
        "# make cell and add it to RNN layer\n",
        "# input_shape = (1,6,5) => number of sequence (batch), length of sequence, size of input dim\n",
        "cell = tf.keras.layers.LSTMCell(units=num_classes, input_shape=(sequence_length, input_dim))\n",
        "tf.model.add(tf.keras.layers.RNN(cell=cell, return_sequences=True))\n",
        "\n",
        "# single LSTM layer can be used as well instead of creating LSTMCell\n",
        "# tf.model.add(tf.keras.layers.LSTM(units=num_classes, input_shape=(sequence_length, input_dim), return_sequences=True))\n",
        "\n",
        "# fully connected layer\n",
        "tf.model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))\n",
        "\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "tf.model.fit(x_one_hot, y_one_hot, epochs=50)\n",
        "tf.model.summary()\n",
        "\n",
        "predictions = tf.model.predict(x_one_hot)\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(prediction)\n",
        "    # print char using argmax, dict\n",
        "    result_str = [idx2char[c] for c in np.argmax(prediction, axis=1)]\n",
        "    print(\"\\tPrediction str: \", ''.join(result_str))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 6, 5)\n",
            "(1, 6, 5)\n",
            "Train on 1 samples\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 415ms/sample - loss: 1.6050 - acc: 0.3333\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 10ms/sample - loss: 1.4339 - acc: 0.3333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 1.3685 - acc: 0.3333\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 1.3084 - acc: 0.3333\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 1.2205 - acc: 0.3333\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 1.1243 - acc: 0.5000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 1.0410 - acc: 0.5000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.9699 - acc: 0.5000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 16ms/sample - loss: 0.9022 - acc: 0.6667\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.8347 - acc: 0.6667\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.7711 - acc: 0.6667\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 6ms/sample - loss: 0.7159 - acc: 0.8333\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.6660 - acc: 0.8333\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 10ms/sample - loss: 0.6120 - acc: 0.8333\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.5460 - acc: 0.8333\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.4708 - acc: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.3954 - acc: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.3142 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.2557 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.1904 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.1489 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 10ms/sample - loss: 0.1108 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.0926 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.0692 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.0577 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.0458 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 6ms/sample - loss: 0.0350 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.0287 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.0242 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0193 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.0155 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0129 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 10ms/sample - loss: 0.0109 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.0081 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0048 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0039 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 6ms/sample - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 7ms/sample - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 20ms/sample - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 8ms/sample - loss: 0.0020 - acc: 1.0000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rnn (RNN)                    multiple                  220       \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri multiple                  30        \n",
            "=================================================================\n",
            "Total params: 250\n",
            "Trainable params: 250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[[1.04614846e-04 9.98340964e-01 1.55243604e-03 1.97204895e-06\n",
            "  5.55176456e-08]\n",
            " [9.99176323e-01 1.27105479e-04 1.07128413e-04 5.87580143e-04\n",
            "  1.87388059e-06]\n",
            " [1.82590069e-04 9.13548283e-04 9.95307386e-01 3.59069020e-03\n",
            "  5.85687940e-06]\n",
            " [1.61539283e-04 1.19920605e-06 2.22525932e-03 9.97590303e-01\n",
            "  2.17371835e-05]\n",
            " [1.24879452e-05 2.15622708e-06 4.84197109e-04 9.98502851e-01\n",
            "  9.98268137e-04]\n",
            " [2.14033062e-05 7.21336255e-06 5.04289710e-05 2.35193031e-04\n",
            "  9.99685764e-01]]\n",
            "\tPrediction str:  ihello\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}